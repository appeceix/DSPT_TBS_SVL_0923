{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combinar Datasets: Concat y Append"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunos de los estudios más interesantes de datos vienen de combinar diferentes fuentes de datos. Estas operaciones pueden involucrar de todo, desde la concatenación de dos datasets diferentes, hasta cosas más complicadas como hacer cruces y uniones de bases de datos que tengan en cuenta solapes de información.\n",
    "\n",
    "Las ``Series`` y los ``DataFrames`` están construídos con este tipo de operaciones en mente, y Pandas incluye diversas funciones y métodos que hacer este tipo de Data Wrangling (manejo de datos) rápido y entendible.\n",
    "\n",
    "Vamos a echarle un vistazo a una simple concatenación de una ``Serie`` y un ``DataFrame`` con el comando pd.concat, luego nos sumergiremos en operaciones más sofisticadas con cruces y uniones en memoria en Pandas.\n",
    "\n",
    "Comencemos con los imports necesarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ahorrarnos algo de tiempo, vamos a definir esta función que crea automáticamente un ``DataFrame`` de una determinada manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fabricador_df(cols, ind):\n",
    "    \"\"\"Super constructor de Dataframes!\"\"\"\n",
    "    data = {c: [str(c) + str(i) for i in ind]\n",
    "            for c in cols}\n",
    "    return pd.DataFrame(data, ind)\n",
    "\n",
    "# ejemplo de DataFrame\n",
    "fabricador_df('ABC', range(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, vamos a crear una clase sencilla que nos permita mostrar varios ``DataFrames`` uno al lado del otro. El código hace uso de un método llamado ``_reprhtml_`` especial, que IPython usa para implementar su potente representación de objetos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class display(object):\n",
    "    \"\"\"Representador HTML de múltiples objetos\"\"\"\n",
    "    template = \"\"\"<div style=\"float: left; padding: 10px;\">\n",
    "    <p style='font-family:\"Courier New\", Courier, monospace'>{0}</p>{1}\n",
    "    </div>\"\"\"\n",
    "    def __init__(self, *args):\n",
    "        self.args = args\n",
    "        \n",
    "    def _repr_html_(self):\n",
    "        return '\\n'.join(self.template.format(a, eval(a)._repr_html_())\n",
    "                         for a in self.args)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '\\n\\n'.join(a + '\\n' + repr(eval(a))\n",
    "                           for a in self.args)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tranquilos, el uso de esto va a ser interesante para la siguiente sección. :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos a repasar: Concatenación de Arrays de Numpy\n",
    "\n",
    "La concatenación de objetos de tipo ``Series y DataFrames`` es muy similar a la concatenación de Numpy Arrays, que ya sabemos que se puede hacer con la función ``np.concatenate`` como vimos en el primer capítulo de Pandas 1.\n",
    "\n",
    "Recordemos, podemos combinar el contenido de dos o más arrays en uno solo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 2, 3]\n",
    "y = [4, 5, 6]\n",
    "z = [7, 8, 9]\n",
    "np.concatenate([x, y, z])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer argumento es una lista o una tupla de Arrays para concatenar. Adicionalmente, requiere de un argumento adicional que nos permite especificar que eje o ``Axis`` queremos combinar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[1, 2],\n",
    "     [3, 4]]\n",
    "np.concatenate([x, x], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenación sencilla con ``pd.concat``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas tiene la función ``pd.concat()`` que nos permite, con una sintaxis similar a ``np.concatenate()`` hacer lo mismo, pero con un número de opciones superior, más adelante las comentaremos:\n",
    "\n",
    "```python\n",
    "# Basado en la versión v0.18 de Pandas\n",
    "pd.concat(objs, axis=0, join='outer', join_axes=None, ignore_index=False,\n",
    "          keys=None, levels=None, names=None, verify_integrity=False,\n",
    "          copy=True)\n",
    "```\n",
    "\n",
    "``pd.concat()`` puede ser usado para unir/concatenar objetos de tipo``Series`` or ``DataFrame``, como hace ``np.concatenate()`` se puede usar para concatenar simples Arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1 = pd.Series(['A', 'B', 'C'], index=[1, 2, 3])\n",
    "print(ser1)\n",
    "ser2 = pd.Series(['D', 'E', 'F'], index=[1, 2, 3])\n",
    "print(ser2)\n",
    "pd.concat([ser1, ser2], axis = 0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podíamos esperar, sirve para concatenar objetos de Alta-Dimensionalidad como nuestro conocido ``DataFrame``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = fabricador_df('AB', [1, 2])\n",
    "df2 = fabricador_df('AB', [1, 2])\n",
    "\n",
    "display('df1','df2','pd.concat([df1, df2], axis=1)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por defecto, la concatenación se hace a nivel fila entre el ``DataFrame`` (por ejemplo, con un ``axis=0``). Como ocurre con ``np.concatenate``, ``pd.concat`` también permite la especificación de un eje o axis por el cual vamos a hacer la concatenación. Vamos a ver este ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = fabricador_df('AB', [0, 1])\n",
    "df4 = fabricador_df('CD', [0, 1])\n",
    "display('df3', 'df4', \"pd.concat([df3, df4], axis=0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si te fijas, podemos usar el equivalente ya conocido de ``axis = 1``. En esencia le estamos diciendo a Pandas que la concatenación tiene que ser a nivel ``Columna``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Índices duplicados\n",
    "\n",
    "Una diferencia ``SUPER IMPORTANTE`` entre los dos métodos de las librerías de Numpy y Pandas es que la concatenación en Pandas mantiene los índices, ``íncluso si tenemos índices duplicados en el resultado``. Vamos a ver un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fabricador_df('AB', [0, 1])\n",
    "y = fabricador_df('AB', [2, 3])\n",
    "y.index = x.index  # Hace índices duplicados! :-O\n",
    "display('x', 'y', 'pd.concat([x, y], axis = 0)') # Siempre debemos resetar los índices para evitar el caos, ahora vemos cómo :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date cuenta que se nos han repetido los índices. Que esto ocurra es válido, este resultado puede ser interesante en ciertas ocasiones. ``pd.concat()`` nos da algunas alternativas.\n",
    "\n",
    "``¿Se te ocurre alguna?``.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capturar las duplicidades como un error:\n",
    "\n",
    "Si quieres que simplemente se verifique la duplicidad de los índices en el resultado de un ``pd.concat()``, podemos especidicar la marca o flac ``verify_integrity``. Con este parámetro a True, la concatenación lanzará una excepción si tenemos índices duplicados. Aquí va un ejemplo, dónde añadimos un print para capturar el mensaje de error en nuestro log:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    pd.concat([x, y], verify_integrity=True)\n",
    "except ValueError as e:\n",
    "    print(\"ValueError:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ignorar el índice:\n",
    "\n",
    "A veces el índice no es del todo necesario y lo mejor es simplemente ignorarlo. Para esta opción podemos usar el parámetro ``ignore_filter``. Cuando se introduce igualado a True, la concatenación se creará con un nuevo entero incremental resultante de la concatenación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display('x', 'y', 'pd.concat([x, y], ignore_index=True)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Añadir múltiples índices:\n",
    "\n",
    "Otra opción es usar el parámetro de ``keys``, que nos ayuda a especificar una etiqueta para cada una de las fuentes; el resultado se representará con un doble índice jerárquico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display('x', 'y', \"pd.concat([x, y], keys=['VISITAS', 'ANALITICAS'])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado será un ``DataFrame indexado``, concepto que ya mostramos en el apartado de Pandas 1, Indexación jerárquica para transformar los datos en la representación gráfica en la que estamos interesados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenación con Joins\n",
    "\n",
    "En los ejemplos que hemos visto, nos hemos centrado en la concatenación de ``DataFrames`` con nombres columnas iguales. En la práctica, los datos que provienen de diferentes fuentes suelen tener diferentes sets de nombres de columnas, en este caso pd.concat ofrece últiles opciones. Consideremos la concatenación de los siguientes ``DataFrames``, como podéis ver, hemos alterado los nombres de columnas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = fabricador_df('ABC', [1, 2])\n",
    "df6 = fabricador_df('BCD', [3, 4])\n",
    "display('df5', 'df6', 'pd.concat([df5, df6])')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por defecto, las combinaciones en las que no hay datos se rellenan con NANs. Para cambiar esto, tenemos que especificar uno de los múltiples inputs que nos ofrecen los parámetros de ``join`` y ``join_axes``. Por defecto, el join es una unión de las columnas input (``join = 'outer'``), pero podemos cambiarlo a una simple intersección, con el valor del parámetro del método ``join='inner'``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display('df5', 'df6',\n",
    "        \"pd.concat([df5, df6], join='inner')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La combinación de las opciones de la función ``pd.concat`` nos permite un amplio abanico de posibles tipos de cruce entre datasets. Tenerlo en cuenta para usarlas en los momentos clave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El método ``append()``\n",
    "\n",
    "Debido a que la concatenación directa de arrays es muy común, Para las ``Series`` y los ``DataFrame`` tenemos también el método ``append`` para poder hacer lo mismo, pero con menos pasos. Por ejemplo, en vez de tener que llamar ``pd.concat([df1, df2])``, podemos usar ``df1.append(df2)``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display('df1', 'df2', 'df1.append(df2)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten muy en cuenta que en los métodos append() y extend() de las listas de Python modifican al propio constructor, ``cosa que no ocurre con este método.`` En el caso de Pandas no se modifica el objeto original, se crea uno nuevo con los datos combinados. Es además un método mucho mñas eficiente, ya que involucra la creación de un nuevo índice y además de un espacio nuevo en la memoria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combinar Datasets: Merge and Join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una característica clave de Pandas es sus operaciones de cruce y unión de alto rendimiento en memoria. Si alguna vez has trabajado con bases de datos, te resultará muy familiar la necesidad de pensar en el consumo de memoria y el tiempo de ejecución en este tipo de operaciones. La mejor manera de comenzar con los cruces es presentando la función de ``pd.merge``. Vamos a ver varios ejemplos de uso.\n",
    "\n",
    "Cómo siempre vamos a hacer uso de nuestra clase ``display()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class display(object):\n",
    "    \"\"\"Display HTML representation of multiple objects\"\"\"\n",
    "    template = \"\"\"<div style=\"float: left; padding: 10px;\">\n",
    "    <p style='font-family:\"Courier New\", Courier, monospace'>{0}</p>{1}\n",
    "    </div>\"\"\"\n",
    "    def __init__(self, *args):\n",
    "        self.args = args\n",
    "        \n",
    "    def _repr_html_(self):\n",
    "        return '\\n'.join(self.template.format(a, eval(a)._repr_html_())\n",
    "                         for a in self.args)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '\\n\\n'.join(a + '\\n' + repr(eval(a))\n",
    "                           for a in self.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algebra Relacional\n",
    "\n",
    "El comportamiento implementado en ``pd.merge`` es una parte de lo que se conoce como algebra relacional, que es un conjunto de reglas formales para manipular datos que son relacionales. Sus bases están presentes en la mayoría de bases de datos relaciones.\n",
    "\n",
    "La fortaleza del algebra relacional es la manera de procesar conjuntamente un conjunto de operaciones *primitivas*, las cuales son la base de un conjunto de operaciones más complejas que se pueden aplicar a cualquier dataset. Con este conjunto de conceptos podremos abordar la totalidad de operaciones.\n",
    "\n",
    "Pandas implementa muchas de estas operaciones *primitivas* o de base en la función ``pd.merge`` y en la de ``pd.join()``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorías de Joins\n",
    "\n",
    "La función ``pd.merge()`` implementa diversos tipos de joins: Los conocidos en inglés como, *one-to-one*, *many-to-one*, and *many-to-many*. Estos tres tipos de cruces son llamados/procesados con la misma función/interfaz de ``pd.merge()``, ahora vamos a ver cómo y cuándo usar cada uno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-to-one joins\n",
    "\n",
    "Quizás el más simple de todas es la unión uno a uno o one-to-one join, que es muy similar a la que hemos visto sobre las concatenaciones orientadas a columnas en el capítulo anterior. \n",
    "\n",
    "Como ejemplo, vamos a tomar dos ``DataFrames`` que contienen información de empleados de una compañia:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'Empleado': ['Jose', 'Jesus', 'Gema', 'Julia'],\n",
    "                    'Departamento': ['Contabilidad', 'Ingenieria', 'Ingenieria', 'RRHH']})\n",
    "df2 = pd.DataFrame({'Empleado': ['Gema', 'Jose', 'Jesus', 'Julia'],\n",
    "                    'Fecha_contratacion': [2004, 2008, 2012, 2014]})\n",
    "display('df1', 'df2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para combinar esta información en un solo ``DataFrame``, podemos usar la función ``pd.merge()`` de esta manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.merge(df1, df2)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función ``pd.merge()`` reconoce que cada ``DataFrame`` tiene una columna empleado, y automáticamente une estas columnas usando esta clave común. El resultado de estea unión es un nuevo ``Dataframe`` que combina la información de estos dos inputs.\n",
    "\n",
    "Acuérdate que el orden de las entradas para cada columna no tiene que mantenerse, en este caso el orden de la columna empleado difiere entre ambos ``DataFrames`` y la función ``pd.merge()`` trabaja con esto correctamente.\n",
    "\n",
    "Adicionalmente, ten en cuenta que la unión por lo general descarta/no usa los índices, a excepción del caso especial de los merges/uniones por índice. (Ver para más detalle las secciones de ``left_index`` y ``right_index``)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many-to-one joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many-to-one joins o las uniones de Muchos-a-Uno son las que una de las dos columnas de clave contiene elementos duplicados. Para estos casos, el ``DataFrame`` resultante preservará los duplicados. Vamos a aplicar a nuestro ejemplo RRHH Database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.DataFrame({'Departamento': ['Contabilidad', 'Ingenieria', 'RRHH',],\n",
    "                    'supervisor': ['Javier', 'Daniela', 'Carlota']})\n",
    "display('df3', 'df4', 'pd.merge(df3, df4)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "El ``DataFrame`` tiene una nueva columna **supervisor**, dónde la información está repetida en una o muchas localizaciones, dónde coincide el campo **Departamento**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many-to-many joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conceptualmente el join Many-to-many o Muchos-a-Muchos es el más complejo, pero es el caso menos común en la práctica. Si las columnas en ambos lados tienen duplicados, el resultado será este tipo de cruce. Vamos con un ejemplo para tenerlo más claro:\n",
    "\n",
    "Considera que tenemos el ``DataFrame`` dónde se muestra las skills o habilidades de cada Departamento. Si hacemos un cruce many-to-many, podemos saber todas las skills de todos los empleados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.DataFrame({'Departamento': ['Contabilidad', 'Contabilidad',\n",
    "                              'Ingenieria', 'Ingenieria', 'RRHH', 'RRHH'],\n",
    "                    'skills': ['Matematicas', 'Hojas de Cálculo', 'Programación', 'Linux',\n",
    "                               'Hojas de Cálculo', 'Organización']})\n",
    "display('df1', 'df5', \"pd.merge(df1, df5)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos tres tipos de Joins pueden ser usados con otras herramientas de Pandas para implementar un gran abanico de funcionalidades. **SPOILER**: En la práctica, los Datasets distan de estar tan limpios cómo el que hemos visto. En la sección siguientes veremos algunas opciones que tiene el ``pd.merge()`` para poder *tunear* las operaciones de cruce.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Especificación de la clave de cruce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya hemos visto el comportamiento que nos da ``pd.merge()`` por defecto. Parece que uno o más nombres de columnas que sean coincidentes de ambos inputs son los que usan para el cruce. Sin embargo, en el mundo real no tenemos nombres iguales en la mayoría de los casos. En este caso, podemos usar las siguientes funcionalidades de ``pd.merge()``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La keyword ``on``:\n",
    "\n",
    "Con esta keywork podremos especificar cuáles son las claves que se van a usar en el cruce. El formato será un nombre de columna o una lista con los diferentes nombres de columna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display('df1', 'df2', \"pd.merge(df1, df2, on='Empleado')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta funcionalidad sólo funcionará si tenemos la columna de Empleado en ambas tablas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Las Keywords ``left_on`` y ``right_on``.\n",
    "\n",
    "En los casos en los que no tengamos los mismos nombres de columna en ambos ``DataFrames``, tendremos que recurrir a estos parámetros para que cómo indica la palabra en inglés, dispongamos los nombres de columnas que van a cada lado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame({'Nombre': ['Jose', 'Jesus', 'Gema', 'Julia'],\n",
    "                    'Salario': [70000, 80000, 120000, 90000]})\n",
    "display('df1', 'df3', 'pd.merge(df1, df3, left_on=\"Empleado\", right_on=\"Nombre\")')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si nos fijamos, ahora tenemos una columna redundante, por lo que podremos usar el método ``drop()`` para eliminar la columna Nombre:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1, df3, left_on=\"Empleado\", right_on=\"Nombre\").drop('Nombre', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Las Keyword ``left_index`` y ``right_index``:\n",
    "\n",
    "En ocasiones, en vez de cruzar por una columna, necesitamos cruzar por un índice de tabla. Por ejemplo, imaginemos este caso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1a = df1.set_index('Empleado')\n",
    "df2a = df2.set_index('Empleado')\n",
    "display('df1a', 'df2a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos usar este índice alfanumérico para unir las columnas usando los parámetros de la función ``pd.merge()``, ``left_index`` y/o ``right_index``: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display('df1a', 'df2a',\n",
    "        \"pd.merge(df1a, df2a, left_index=True, right_index=True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para solucionarnos la vida, el objeto ``DataFrame`` tiene el método ``join()`` que realiza un cruce por índice por defecto, veamos un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display('df1a', 'df2a', 'df1a.join(df2a)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si lo que nos interesa es hacer un mix de índices y columnas a la hora de cruzar, podremos usar indistintamente las columnas de ``left_index`` con ``right_on`` o ``left_on`` con ``right_index`` para llegar al mismo resultado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display('df1a', 'df3', \"pd.merge(df1a, df3, left_index=True, right_on='Nombre')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas estas opciones funcionan también con índices múltibles o con múltiples columnas, la interfaz para este caso es igualmente simple. Para más información sobre los cruces, podemos recurrir siempre a esta excelente sección de la documentación oficial: [\"Merge, Join, and Concatenate\" section](http://pandas.pydata.org/pandas-docs/stable/merging.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Especificar conjuntos aritméticos para los Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los ejemplos anteriores, hemos visto muchas de las consideraciones a la hora de hacer Joins de Pandas. Una que no hemos tocado ha sido el conjunto aritmético usado en un Join. ¿Qué es un conjunto aritmético? Veámoslo con un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = pd.DataFrame({'Nombre': ['Pedro', 'Pablo', 'Maria'],\n",
    "                    'Comida': ['Pescado', 'Alubias', 'Pan']},\n",
    "                   columns=['Nombre', 'Comida'])\n",
    "df7 = pd.DataFrame({'Nombre': ['Maria', 'Jose'],\n",
    "                    'Bebida': ['Vino', 'Cerveza']},\n",
    "                   columns=['Nombre', 'Bebida'])\n",
    "display('df6', 'df7', 'pd.merge(df6, df7)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos dos Datasets que tienen sólo un registro en común según su clave de cruce, María. En las tablas no tenemos el mismo conjunto de variables o features para cada persona, por lo que perdemos información, **tienen diferentes conjuntos aritméticos.** Por defecto, el resultado contiene la intersección de dos sets de inputs. Esto ya lo hemos conocido como *inner join*. Podemos especificar cómo queremos hacer el cruce con la keywork o parámetro ``how=`` que por defecto es ``\"inner\"``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df6, df7, how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las otras opciones serían ``outer``, ``left`` y ``right``. Acordémonos que *outer join* devuelve un cruce sobre la unión del input de columnas, y las rellena en caso no coincidente con NAs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display('df6', 'df7', \"pd.merge(df6, df7, how='outer')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El *left join* y el *right join* por su parte, devuelve el cruce sobre las entradas de la izquierda o de la derecha respectivamente. Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display('df6', 'df7', \"pd.merge(df6, df7, how='left')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display('df6', 'df7', \"pd.merge(df6, df7, how='right')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si os fijáis, el output de filas corresponde con las entradas/filas que teníamos en el input izquierdo. Usando el parámetro ``how='right'`` el funcionamiento es el mismo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solapar los nombres de columna: La Keyword ``suffixes``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, puedes acabar en un caso en el que dos inputs o ``DataFrames`` tengas de nombres de columna en conflicto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8 = pd.DataFrame({'Nombre': ['Pepe', 'Joaquin', 'Laura', 'Sofia'],\n",
    "                    'Rango': [1, 2, 3, 4]})\n",
    "df9 = pd.DataFrame({'Nombre': ['Pepe', 'Joaquin', 'Laura', 'Sofia'],\n",
    "                    'Rango': [3, 1, 4, 2]})\n",
    "display('df8', 'df9', 'pd.merge(df8, df9, on=\"Nombre\")')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como tenemos un output con dos columnas en conflicto, la función de ``pd.merge()`` es inteligente y pondrá por defento los sufijos de ``_x`` y ``_y`` para hacerlas únicas. Si los resultados son algo *feos* podemos recurrir al parámetro del método ``suffixes``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display('df8', 'df9', 'pd.merge(df8, df9, on=\"Nombre\", suffixes=[\"_L\", \"_R\"])')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos sufijos funcionan con cualquier configuración vista de los Joins, también con múltiples columnas en conflicto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para más información sobre estos casos podéis ver también la sección que vimos anteiormente en **Pandas 1 de Agregación y agrupación** donde tenemos más contexto sobre el álgebra relacional. También podemos acudir a esta sección de la documentación oficial de pandas [Pandas \"Merge, Join and Concatenate\" documentation](http://pandas.pydata.org/pandas-docs/stable/merging.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos con un ejemplo: US States Data\n",
    "\n",
    "Vamos a realizar operaciones de cruce y unión con diferentes orígenes de datos. Aquí vamos a usar un ejemplo de datos acerca de los estados de (valga la redundancia) de Estados Unidos de América y su población."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos usar estan sentencias de shell (Linux) para descargarlo, pero ya lo tenemos. ¿Sabrías hacerlo para Windows?\n",
    "#!curl -O https://raw.githubusercontent.com/jakevdp/data-USstates/master/state-population.csv\n",
    "#!curl -O https://raw.githubusercontent.com/jakevdp/data-USstates/master/state-areas.csv\n",
    "#!curl -O https://raw.githubusercontent.com/jakevdp/data-USstates/master/state-abbrevs.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero vamos a usar la función de Pandas ``read_csv()``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pd.read_csv('data/state-population.csv')\n",
    "areas = pd.read_csv('data/state-areas.csv')\n",
    "abbrevs = pd.read_csv('data/state-abbrevs.csv')\n",
    "\n",
    "display('pop', 'areas', 'abbrevs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo esta información, digamos que queremos computar un resultado sencillo (de primeras): Ordenar por rango los estados y territorios por su densidad de población de 2010. Claramente tenemos los datos necesarios para encontrar el resultado, pero tenemos que, en primer lugar, combinar los tres ``DataFrames``.\n",
    "\n",
    "Empezaremos haciendo un **Many-to-one** que nos dará el nombre del estado completo con su población. Queremos cruzar basándonos en el campo ``state/region`` columna de la tabla ``pop`` y de ``abbreviation`` (abreviación), columna de la tabla ``abbrevs``. Usaremos el tipo de cruce *Outer* para asegurar que ningún dato se nos pierda en el cruce, tenga o no coincidencia en todas las tablas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(pop, abbrevs, how='outer',\n",
    "                  left_on='state/region', right_on='abbreviation')\n",
    "merged = merged.drop('abbreviation', axis = 1) # Nos quitamos los duplicados\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a asegurarnos de que no tengamos ningúna pérdida de información por aquí, la mejor manera es evaluar si tenemos nulos en las columnas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ouch! Tenemos nulos en la columna de ``population``, vamos a ver dónde pueden estan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[merged['population'].isnull()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que Puerto Rico no tiene valores de población para algunos años de principios de los 90; probablemente se trata de que no tenemos ese dato en su fuente correspondiente.\n",
    "\n",
    "Lo más importante es que algunos de estos nuevos estados también pueden estar en Null, ¡lo que significa que tenemos que estar atentos con la key de abreviatura (``abbrevs``)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.loc[merged['state'].isnull(), 'state/region'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos rapidamente inferir el problema que tenemos, nuestros datos de población incluyen entradas de Puerto Rico (PR) y el campo estado parece ser (USA), pero no tenemos esa información en la tabla de abreviaturas para la key que en este caso es PR. Lo que podemos hacer es añadir esta información para los casos que hemos visto que están nulos directamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.loc[merged['state/region'] == 'PR', 'state'] = 'Puerto Rico'\n",
    "merged.loc[merged['state/region'] == 'USA', 'state'] = 'United States'\n",
    "merged.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos hemos librado de los nulos en la columna de ``state``.\n",
    "\n",
    "Vamos a seguir un procedimiento similar con los datos de área. Examinando nuestros resultado, querremos unir con también con la columna ``state``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.merge(merged, areas, on='state', how='left')\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De nuevo, vemos si tenemos nulos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos algunos nulos en la columna ``area``, vamos a echar un vistazo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['state'][final['area (sq. mi)'].isnull()].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que nuestro ``DataFrame`` de areas no tiene datos de area correspondientes de los Estados Unidos (United States) como conjunto. Podríamos insertar el valor correcto, usando por ejemplo la suma de todas las areas de todos los estados, pero para este caso (para no complicarnos la vida) vamos a simplemente quitar los valores nulos y con ellos toda la información relativa a los Estados Unidos como conjunto ya que no es tan relevante para el análisis en cuestión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.dropna(inplace=True)\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos los datos que necesitamos, vamos a responder a nuestra pregunta, primero vamos a ver la poción de datos correspondiente con el año 2000, y su población total. Vamos usar la función ``query()`` en este caso para hacer esto más rapidamente.\n",
    "\n",
    "(**¿Es la primera vez que la véis, cierto?**)\n",
    "\n",
    "En el caso de no tener disponible la función, es posible que necesitemos la librería ``numexpr``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2010 = final.query(\"year == 2010 & ages == 'total'\")\n",
    "data2010.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a computar la densidad de población y mostrarla en orden. **Pero primero lo más importante, reindexar los datos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2010.set_index('state', inplace=True)\n",
    "density = data2010['population'] / data2010['area (sq. mi)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density.sort_values(ascending=False, inplace=True)\n",
    "density.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2010['papa'] = data2010['population'] / data2010['area (sq. mi)']\n",
    "data2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado es un ranking de los Estados de US además de Washinton DC y Puerto Rico, en orden, según el censo de población de 2010 y con sus residentes por milla cuadrada.\n",
    "\n",
    "Vamos a ver los estados que tienen menos densidad de población:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el Estado menos poblado (y con diferencia) es Alaska, prácticamente tiene un residente por milla cuadrada (WOW). Este tipo de trabajo con los datos es muy común, espero que este ejemplo con datos del mundo real te haya servido para hacerte una idea de cómo poder combinar las fuentes de datos correctamente para calcular lo necesario para llegar al resultado planteado."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec2a379ed5c25334a484232182c9d38ef8bd9861e2542d0c517568c4f99a9a7c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
